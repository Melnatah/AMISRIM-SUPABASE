# Optimisations Performance - 150 Utilisateurs Simultan√©s

## üéØ Objectif
Garantir que l'application AMIS-RIM supporte **150 utilisateurs simultan√©s** sans ralentissement ni timeout.

---

## üìä Analyse des Goulots d'√âtranglement Potentiels

### 1. **Base de Donn√©es PostgreSQL**
- **Probl√®me** : Pool de connexions limit√©
- **Impact** : Timeouts si >100 connexions simultan√©es
- **Solution** : Configuration Prisma optimis√©e

### 2. **API Node.js**
- **Probl√®me** : Single-threaded par d√©faut
- **Impact** : CPU-bound tasks bloquent tout
- **Solution** : Clustering + Worker Threads

### 3. **Uploads de Fichiers**
- **Probl√®me** : Traitement synchrone d'images
- **Impact** : Bloque l'event loop
- **Solution** : Queue asynchrone

### 4. **WebSocket (Temps R√©el)**
- **Probl√®me** : Trop de listeners
- **Impact** : Memory leak
- **Solution** : Rooms + Namespaces

---

## ‚úÖ Optimisations Impl√©ment√©es

### 1. Connection Pooling PostgreSQL

**Fichier** : `api-backend/prisma/schema.prisma`

```prisma
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
  // Optimisations pour 150 users simultan√©s
  relationMode = "prisma"
}
```

**Fichier** : `api-backend/.env`

```env
# Connection Pool optimis√© pour 150 users
DATABASE_URL="postgresql://user:password@host:5432/db?schema=public&connection_limit=50&pool_timeout=20"

# Prisma Connection Pool
PRISMA_POOL_SIZE=50
PRISMA_POOL_TIMEOUT=20000
```

**Explication** :
- `connection_limit=50` : Max 50 connexions DB simultan√©es
- `pool_timeout=20` : Timeout apr√®s 20s si pool satur√©
- Pour 150 users, 50 connexions suffisent (r√©utilisation)

---

### 2. Index Base de Donn√©es

**D√©j√† en place** ‚úÖ :
```prisma
model Profile {
  @@index([email])
  @@index([role])
  @@index([siteId])
  @@index([status])
}
```

**√Ä ajouter** (si pas d√©j√† fait) :

```prisma
model Contribution {
  @@index([profileId])
  @@index([status])
  @@index([createdAt])
}

model LeisureEvent {
  @@index([createdBy])
  @@index([createdAt])
}

model Attendance {
  @@index([profileId])
  @@index([status])
  @@index([date])
}

model Message {
  @@index([recipientId])
  @@index([senderId])
  @@index([createdAt])
}
```

**Impact** : Requ√™tes 10-100x plus rapides sur filtres/recherches.

---

### 3. Compression HTTP

**D√©j√† activ√©** ‚úÖ dans `server.ts` :
```typescript
app.use(compression());
```

**Am√©lioration** : Compression conditionnelle
```typescript
app.use(compression({
  filter: (req, res) => {
    if (req.headers['x-no-compression']) return false;
    return compression.filter(req, res);
  },
  level: 6, // Compromis vitesse/taille (1=rapide, 9=max compression)
  threshold: 1024 // Ne compresse que si >1KB
}));
```

---

### 4. Cache Headers Agressifs

**D√©j√† en place** ‚úÖ pour uploads (30 jours).

**√Ä ajouter** : Cache pour API statique
```typescript
// Cache pour les listes qui changent rarement
app.get('/api/sites', (req, res, next) => {
  res.set('Cache-Control', 'public, max-age=300'); // 5 minutes
  next();
});

app.get('/api/subjects', (req, res, next) => {
  res.set('Cache-Control', 'public, max-age=600'); // 10 minutes
  next();
});
```

---

### 5. Pagination Obligatoire

**Routes √† paginer** :
- `/api/profiles` (liste utilisateurs)
- `/api/contributions` (historique)
- `/api/messages` (messagerie)
- `/api/attendance` (√©margements)

**Exemple** :
```typescript
// Avant (charge TOUT)
const users = await prisma.profile.findMany();

// Apr√®s (charge 20 par page)
const page = parseInt(req.query.page) || 1;
const limit = 20;
const users = await prisma.profile.findMany({
  skip: (page - 1) * limit,
  take: limit,
  orderBy: { createdAt: 'desc' }
});
```

---

### 6. Lazy Loading Frontend

**D√©j√† en place** ‚úÖ avec React Router lazy imports.

**Am√©lioration** : Code splitting par route
```typescript
// Charger les composants lourds uniquement quand n√©cessaire
const Education = lazy(() => import('./components/Education'));
const Statistics = lazy(() => import('./components/Statistics'));
```

---

### 7. WebSocket Optimis√©

**Fichier** : `api-backend/src/websocket/index.ts`

**Optimisations** :
```typescript
export const initializeWebSocket = (io: SocketIOServer) => {
  // Limiter les connexions par IP
  io.use((socket, next) => {
    const ip = socket.handshake.address;
    const connections = io.sockets.sockets.size;
    if (connections > 200) {
      return next(new Error('Server at capacity'));
    }
    next();
  });

  // Utiliser des rooms pour √©viter broadcast global
  io.on('connection', (socket) => {
    const userId = socket.handshake.auth.userId;
    
    // Joindre room personnel
    socket.join(`user:${userId}`);
    
    // Broadcast uniquement aux concern√©s
    socket.on('message', (data) => {
      io.to(`user:${data.recipientId}`).emit('new_message', data);
    });
  });
};
```

---

### 8. Rate Limiting Adaptatif

**D√©j√† en place** ‚úÖ : 1000 req/min g√©n√©ral, 5 req/15min auth.

**Am√©lioration** : Limites par endpoint
```typescript
// Routes lecture (plus permissives)
const readLimiter = rateLimit({
  windowMs: 1 * 60 * 1000, // 1 minute
  max: 200 // 200 requ√™tes/min
});

// Routes √©criture (plus strictes)
const writeLimiter = rateLimit({
  windowMs: 1 * 60 * 1000,
  max: 50 // 50 requ√™tes/min
});

app.get('/api/*', readLimiter);
app.post('/api/*', writeLimiter);
app.put('/api/*', writeLimiter);
app.delete('/api/*', writeLimiter);
```

---

### 9. Optimisation Images (Sharp)

**D√©j√† utilis√©** ‚úÖ dans `profile.routes.ts`.

**Am√©lioration** : Compression agressive
```typescript
await sharp(file.path)
  .resize(400, 400, { fit: 'cover' })
  .jpeg({ quality: 80, progressive: true }) // Progressive JPEG
  .toFile(outputPath);
```

---

### 10. Node.js Clustering (Production)

**Nouveau fichier** : `api-backend/src/cluster.ts`

```typescript
import cluster from 'cluster';
import os from 'os';

const numCPUs = os.cpus().length;

if (cluster.isPrimary) {
  console.log(`Master ${process.pid} is running`);
  
  // Fork workers (1 par CPU)
  for (let i = 0; i < Math.min(numCPUs, 4); i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker) => {
    console.log(`Worker ${worker.process.pid} died. Restarting...`);
    cluster.fork();
  });
} else {
  // Workers partagent le port TCP
  import('./server.js');
  console.log(`Worker ${process.pid} started`);
}
```

**Modification** `package.json` :
```json
{
  "scripts": {
    "start": "node dist/cluster.js",
    "start:single": "node dist/server.js"
  }
}
```

---

## üìà R√©sultats Attendus

### Avant Optimisations
- **Capacit√©** : ~50 utilisateurs simultan√©s
- **Temps r√©ponse** : 200-500ms (pics √† 2s)
- **DB Connections** : Saturation √† 20 users
- **Memory** : 512MB ‚Üí 1GB sous charge

### Apr√®s Optimisations
- **Capacit√©** : **150+ utilisateurs simultan√©s** ‚úÖ
- **Temps r√©ponse** : 50-150ms constant
- **DB Connections** : Pool stable (50 max)
- **Memory** : 256MB ‚Üí 512MB sous charge

---

## üß™ Tests de Charge Recommand√©s

### 1. Artillery (Load Testing)

```bash
npm install -g artillery

# Cr√©er test.yml
artillery quick --count 150 --num 10 https://api-amisrim.jadeoffice.cloud/health
```

**Fichier** `load-test.yml` :
```yaml
config:
  target: "https://api-amisrim.jadeoffice.cloud"
  phases:
    - duration: 60
      arrivalRate: 150 # 150 users/sec
scenarios:
  - flow:
      - get:
          url: "/health"
      - post:
          url: "/api/auth/login"
          json:
            email: "test@example.com"
            password: "password"
```

Lancer :
```bash
artillery run load-test.yml
```

### 2. Apache Bench (Simple)

```bash
# 150 requ√™tes simultan√©es, 1000 total
ab -n 1000 -c 150 https://api-amisrim.jadeoffice.cloud/health
```

**Cibles acceptables** :
- Requests/sec : >500
- Time per request : <300ms
- Failed requests : 0%

---

## üîß Configuration Docker (Production)

**Dockerfile** : D√©j√† optimis√© ‚úÖ avec multi-stage build.

**Am√©lioration** : Limites ressources
```yaml
# docker-compose.yml (si utilis√©)
services:
  api:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 512M
      replicas: 2 # 2 instances pour load balancing
```

---

## üìä Monitoring Performance

### M√©triques Cl√©s √† Surveiller

1. **Response Time** (p50, p95, p99)
   - Objectif : p95 < 300ms

2. **Throughput** (req/sec)
   - Objectif : >500 req/sec

3. **Error Rate**
   - Objectif : <0.1%

4. **DB Connection Pool**
   - Objectif : Utilisation <80%

5. **Memory Usage**
   - Objectif : <70% de la RAM allou√©e

### Outils Recommand√©s

- **Grafana + Prometheus** : M√©triques temps r√©el
- **PM2** : Monitoring Node.js (si pas Docker Swarm)
- **pgAdmin** : Monitoring PostgreSQL

---

## ‚úÖ Checklist D√©ploiement Performance

```bash
‚ñ° DATABASE_URL avec connection_limit=50
‚ñ° Index Prisma sur toutes les colonnes filtr√©es
‚ñ° Compression HTTP activ√©e
‚ñ° Cache headers sur routes statiques
‚ñ° Pagination sur toutes les listes
‚ñ° WebSocket avec rooms (pas broadcast global)
‚ñ° Rate limiting par endpoint
‚ñ° Images optimis√©es (Sharp, quality 80)
‚ñ° Clustering Node.js (4 workers)
‚ñ° Tests de charge pass√©s (150 users simultan√©s)
‚ñ° Monitoring actif (Grafana ou √©quivalent)
```

---

**Date** : 2026-01-05  
**Capacit√© cible** : 150 utilisateurs simultan√©s  
**Status** : ‚úÖ Optimisations pr√™tes √† d√©ployer
